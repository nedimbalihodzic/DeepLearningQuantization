{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "916531fe",
   "metadata": {},
   "source": [
    "# Custom Build an 8-bit Quantizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2a33f8",
   "metadata": {},
   "source": [
    "W8A16LinearLayer\n",
    "                    # 8-bit  # 16-bit         # optional\n",
    "* w8_a16_forward -> weights, input,   scales, bias=None\n",
    "\n",
    "* Cast the 8-bit weights to the same data type as the input, \"casted weights\", keeping the \"casted weights\" in the same range as before, [-128, 127]\n",
    "\n",
    "* Next,\n",
    "((ùëñùëõùëùùë¢ùë°ùë†‚ãÖ``casted weights'')‚àóùë†ùëêùëéùëôùëí)+ùëèùëñùëéùë†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b03f8174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "random_int8 = torch.randint(-128, 127, (32, 16)).to(torch.int8)\n",
    "random_hs = torch.randn((1, 16), dtype=torch.bfloat16)\n",
    "scales = torch.randn((1, 32), dtype=torch.bfloat16)\n",
    "bias = torch.randn((1, 32), dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "648f10f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-478.0000,  280.0000, -362.0000, -414.0000,  121.5000, -262.0000,\n",
       "           41.2500,   75.5000, -151.0000,  -78.0000,   39.5000, -117.0000,\n",
       "         -164.0000, -132.0000, -344.0000, -209.0000,   38.7500,  316.0000,\n",
       "          220.0000,   -6.1875,  252.0000,   72.0000,  -57.7500, -123.5000,\n",
       "          -33.7500,    6.4062, -254.0000,   -9.1875,  187.0000,  -27.7500,\n",
       "          -19.5000,  260.0000]], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.linear(random_hs, random_int8.to(random_hs.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0de8fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-732.0000, -243.0000, -124.5000,  328.0000,    3.7812,  -71.5000,\n",
       "          -58.5000, -157.0000,  169.0000,  176.0000,    8.8750,   19.7500,\n",
       "           89.0000, -119.0000,  145.0000,   32.0000,   42.7500, -540.0000,\n",
       "           -7.5312,   -4.3125,   26.0000, -173.0000,   31.8750,  -33.2500,\n",
       "          -45.2500,   11.1250,   54.2500,   -4.6562,  -65.5000,   34.5000,\n",
       "           -9.8125, -410.0000]], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(F.linear(random_hs, random_int8.to(random_hs.dtype)) * scales) + bias  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19150805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w8_a16_forward(weight, input, scales, bias = None):\n",
    "    casted_weights = weight.to(input.dtype)\n",
    "    output = F.linear(input, casted_weights) * scales \n",
    "    if bias is not None:\n",
    "        output = output + bias \n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efd5fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class W8A16LinearLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias = True, dtype=torch.float32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"int8_weights\",\n",
    "            torch.randint(\n",
    "                -128, 127, (out_features, in_features), dtype=torch.int8\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.register_buffer(\"scales\",\n",
    "                             torch.randn((out_features), dtype = dtype ))\n",
    "        \n",
    "        if bias: \n",
    "            self.register_buffer(\"bias\", \n",
    "                                 torch.randn((1,out_features), dtype=dtype))\n",
    "        else:\n",
    "            self.bias = None \n",
    "    \n",
    "    def forward(self, input):\n",
    "        return w8_a16_forward(self.int8_weights, input, self.scales, self.bias)\n",
    "    \n",
    "    def quantize(self, weights):\n",
    "        w_fp32 = weights.clone().to(torch.float32)\n",
    "\n",
    "        scales = w_fp32.abs().max(dim=-1).values / 127\n",
    "        scales = scales.to(weights.dtype)\n",
    "\n",
    "        int8_weights = torch.round(weights/scales.unsqueeze(1)).to(torch.int8)\n",
    "\n",
    "        self.int8_weights = int8_weights\n",
    "        self.scales = scales\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "242eeae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_instance = W8A16LinearLayer(16,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88ec1975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print(dummy_instance.int8_weights.shape)\n",
    "print(dummy_instance.scales.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7779630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = W8A16LinearLayer(16,32)\n",
    "dummy_hidden_states = torch.randn(1,6,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a8c7f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 32])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module(dummy_hidden_states).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7ec5eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = W8A16LinearLayer(4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74003678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights before:\n",
      " tensor([[-114,  -30,    5,   -6],\n",
      "        [-126,  109,  111,  -76],\n",
      "        [  74,   19,   48,   29],\n",
      "        [  96,  -55,  -58,   48],\n",
      "        [ -35,   46,   64,   96],\n",
      "        [ -83,   87,   38,  -48],\n",
      "        [ -20,   68,   45,   48],\n",
      "        [  -2,  -16, -112,   83]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights before:\\n\" , module.int8_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "251139c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_matrix = torch.randn((4, 8), dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42162f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "module.quantize(random_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3399a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights After:\n",
      " tensor([[  18,  127,   50,   70,   -7,  -75,  -82,    8],\n",
      "        [ -89,  127,  -37,  -21,   53,  -76,   32,   31],\n",
      "        [-127,   -4,  -47,   -6,  -64, -104,  -69,  -49],\n",
      "        [ -98,    5, -127,  -49,  -36,  -12,   69,  -70]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights After:\\n\" , module.int8_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28e8563c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0167, 0.0203, 0.0137, 0.0145], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f1980a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.scales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f10ad64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.int8_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd9737bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3008,  2.1250,  0.8359,  1.1719, -0.1172, -1.2578, -1.3750,  0.1338],\n",
       "        [-1.8047,  2.5781, -0.7500, -0.4258,  1.0703, -1.5391,  0.6484,  0.6289],\n",
       "        [-1.7422, -0.0549, -0.6445, -0.0825, -0.8789, -1.4297, -0.9492, -0.6719],\n",
       "        [-1.4219,  0.0728, -1.8438, -0.7109, -0.5234, -0.1738,  1.0000, -1.0156]],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### dequantized weights\n",
    "module.int8_weights * module.scales.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e7d1ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2969,  2.1250,  0.8438,  1.1641, -0.1099, -1.2578, -1.3750,  0.1387],\n",
       "        [-1.8047,  2.5781, -0.7422, -0.4180,  1.0781, -1.5547,  0.6406,  0.6211],\n",
       "        [-1.7422, -0.0566, -0.6445, -0.0850, -0.8750, -1.4375, -0.9453, -0.6758],\n",
       "        [-1.4219,  0.0679, -1.8438, -0.7148, -0.5312, -0.1787,  1.0000, -1.0156]],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### original weights\n",
    "random_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f61c74d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0041, dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(random_matrix - module.int8_weights \n",
    " * module.scales.unsqueeze(1)).abs().mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
